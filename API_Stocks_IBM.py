# -*- coding: utf-8 -*-
"""Test.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1M6KPafWyBwaId5JdgSGmIGJZXUOo9OOz
"""

import requests

url = "https://finance-social-sentiment-for-twitter-and-stocktwits.p.rapidapi.com/get-content"

querystring = {"tickers":"IBM","extended":"false","limit":"50"}

headers = {
	"Content-Type": "application/json",
	"X-RapidAPI-Key": "882d02a1abmsha77e33251fca8f0p18cd3djsnc306df8cca34",
	"X-RapidAPI-Host": "finance-social-sentiment-for-twitter-and-stocktwits.p.rapidapi.com"
}

response = requests.get(url, headers=headers, params=querystring)

print(response.json())

import requests

url = "https://real-time-finance-data.p.rapidapi.com/search"

querystring = {"query":"IBM","language":"en"}

headers = {
	"X-RapidAPI-Key": "882d02a1abmsha77e33251fca8f0p18cd3djsnc306df8cca34",
	"X-RapidAPI-Host": "real-time-finance-data.p.rapidapi.com"
}

response = requests.get(url, headers=headers, params=querystring)

print(response.json())

import requests

url = "https://finance-social-sentiment-for-twitter-and-stocktwits.p.rapidapi.com/get-alerts"

querystring = {"notificationTypes":"financial-news","tickers":"IBM"}

headers = {
	"Content-Type": "application/json",
	"X-RapidAPI-Key": "882d02a1abmsha77e33251fca8f0p18cd3djsnc306df8cca34",
	"X-RapidAPI-Host": "finance-social-sentiment-for-twitter-and-stocktwits.p.rapidapi.com"
}

response = requests.get(url, headers=headers, params=querystring)

print(response.json())





import requests
import nltk
from nltk.sentiment import SentimentIntensityAnalyzer

# Download the required resources for sentiment analysis
nltk.download('vader_lexicon')
url = "https://finance-social-sentiment-for-twitter-and-stocktwits.p.rapidapi.com/get-alerts"

querystring = {"notificationTypes": "financial-news", "tickers": "IBM"}

headers = {
    "Content-Type": "application/json",
    "X-RapidAPI-Key": "882d02a1abmsha77e33251fca8f0p18cd3djsnc306df8cca34",
    "X-RapidAPI-Host": "finance-social-sentiment-for-twitter-and-stocktwits.p.rapidapi.com"
}

response = requests.get(url, headers=headers, params=querystring)
data = response.json()

# Extracting relevant information
relevant_info = []

for item in data:
    if 'title' in item:
        info = {
            'title': item['title'],
            'ticker': item['ticker'],
            'createdAt': item['createdAt'],
            'industry': item['prices']['industry'],
            'sector': item['prices']['sector'],
            'content': item['contentTextBrief'],
            'url': item['url']
        }

        # Perform sentiment analysis on the tweet content
        sia = SentimentIntensityAnalyzer()
        sentiment_scores = sia.polarity_scores(info['content'])
        info['sentiment'] = sentiment_scores['compound']

        relevant_info.append(info)

# Printing the extracted information and sentiment analysis results
for info in relevant_info:
    print('Title:', info['title'])
    print('Ticker:', info['ticker'])
    print('Created At:', info['createdAt'])
    print('Industry:', info['industry'])
    print('Sector:', info['sector'])
    print('Content:', info['content'])
    print('URL:', info['url'])
    print('Sentiment:', info['sentiment'])
    print()

# Financial factors
peg_ratio = 4.73  # Higher PEG ratio indicates a less favorable investment
eps = 2.24  # Earnings per share
earning_growth_ratio = 0.253  # Earnings growth rate

# Define your criteria and weightage
sentiment_weight = 0.2  # Weightage for sentiment score
peg_weight = 0.2  # Weightage for PEG ratio
eps_weight = 0.4  # Weightage for EPS
earning_growth_ratio_weight = 0.2  # Weightage for earning growth ratio

# Calculate the average sentiment score (replace with your own calculation)
average_sentiment_score = 0.5

# Combine sentiment score with financial factors using the defined weightage
investment_score = (
    sentiment_weight * average_sentiment_score +
    peg_weight * (1 / peg_ratio) +  # Invert PEG ratio for better scores with lower ratios
    eps_weight * eps +
    earning_growth_ratio_weight * earning_growth_ratio
)


# Determine if one can invest in IBM based on sentiment analysis and financial factors
if investment_score > 0.8:
    print("Investment score:", investment_score)
    print("Overall positive sentiment and favorable financial factors. One can consider investing in IBM.")
else:
    print("Investment score:", investment_score)
    print("Investment decision should be based on further analysis of sentiment and financialÂ factors.")

pip install confluent-kafka





from google.colab import files
uploaded = files.upload()

from confluent_kafka import Producer

def read_ccloud_config(config_file):
    conf = {}
    with open(config_file) as fh:
        for line in fh:
            line = line.strip()
            if len(line) != 0 and line[0] != "#":
                parameter, value = line.strip().split('=', 1)
                conf[parameter] = value.strip()
    return conf

file_path = '/content/client.properties'  # Update with the correct file path
producer = Producer(read_ccloud_config(file_path))
producer.produce("Ibm_stocks", key="O3OGN2E2YXGSQTFF", value="51YEWKgezN90BHLRG97EZYowPRJ/3zZhqcyusf9g+A/1yGHecUYi1mWQM4eKejjs")



producer = Producer(read_ccloud_config("/content/client.properties"))
producer.produce("Ibm_stocks", key="O3OGN2E2YXGSQTFF  ", value="51YEWKgezN90BHLRG97EZYowPRJ/3zZhqcyusf9g+A/1yGHecUYi1mWQM4eKejjs")



from confluent_kafka import Producer
producer = Producer(read_ccloud_config("/content/client.properties"))
producer.produce("Ibm_stocks", key="O3OGN2E2YXGSQTFF  ", value="51YEWKgezN90BHLRG97EZYowPRJ/3zZhqcyusf9g+A/1yGHecUYi1mWQM4eKejjs+CsgOVVGpfQhHIY4WZbZZ2yu0+Y+Nr5ujPSJxHM")

from confluent_kafka import Consumer

props = read_ccloud_config("client.properties")
props["group.id"] = "python-group-1"
props["auto.offset.reset"] = "earliest"

consumer = Consumer(props)
consumer.subscribe(["Ibm_stocks"])
try:
    while True:
     msg = consumer.poll(1.0)
     if msg is not None and msg.error() is None:
         print("key = {key:12} value = {value:12}".format(key=msg.key().decode('utf-8'), value=msg.value().decode('utf-8')))
except KeyboardInterrupt:
 pass
finally:
         consumer.close()

import json
from confluent_kafka import Producer



def read_ccloud_config(file_path):
    # Read the configuration properties from the file
    # and return a dictionary of Kafka configuration
    config = {
        'bootstrap.servers': 'your_bootstrap_servers',
        'schema.registry.url': 'your_schema_registry_url',
        'sasl.mechanisms': 'PLAIN',
        'sasl.username': 'your_sasl_username',
        'sasl.password': 'your_sasl_password',
        'security.protocol': 'SASL_SSL'
    }
    return config



file_path = '/content/client.properties'
producer = Producer(read_ccloud_config(file_path))



# Assuming you have fetched data and stored it in the 'response' variable
data = response.json()



record_value = json.dumps(data)
producer.produce(topic, key=str(delivered_records), value=record_value, on_delivery=acked)

from confluent_kafka import Producer
import requests

def read_ccloud_config(config_file):
    # Implement your logic to read the ccloud config file
    # and return the configuration dictionary
    # Example:
    config = {
        'bootstrap.servers': 'your-bootstrap-servers',
        'sasl.username': 'your-username',
        'sasl.password': 'your-password',
        'security.protocol': 'SASL_SSL',
        'sasl.mechanism': 'PLAIN',
    }
    return config

def produce_message(topic, key, value):
    producer = Producer(read_ccloud_config("/content/client.properties"))
    producer.produce(topic, key=key, value=value)
    producer.flush()

# API request
url = "https://real-time-finance-data.p.rapidapi.com/search"
querystring = {"query": "IBM", "language": "en"}
headers = {
    "X-RapidAPI-Key": "882d02a1abmsha77e33251fca8f0p18cd3djsnc306df8cca34",
    "X-RapidAPI-Host": "real-time-finance-data.p.rapidapi.com"
}
response = requests.get(url, headers=headers, params=querystring)
data = response.json()

record_value = json.dumps(Schema)
producer.produce(topic, key=str(delivered_records), value=record_value, on_delivery=acked)

from confluent_kafka import Consumer, KafkaError

def read_ccloud_config(config_file):
    # Implement your logic to read the ccloud config file
    # and return the configuration dictionary
    # Example:
    config = {
        'bootstrap.servers': 'your-bootstrap-servers',
        'sasl.username': 'your-username',
        'sasl.password': 'your-password',
        'security.protocol': 'SASL_SSL',
        'sasl.mechanism': 'PLAIN',
        'group.id': 'your-consumer-group-id'
    }
    return config

# Kafka consumer configuration
consumer_conf = read_ccloud_config("/content/client.properties")
consumer_conf['auto.offset.reset'] = 'earliest'  # Start consuming from the beginning of the topic

# Create Kafka consumer
consumer = Consumer(consumer_conf)
consumer.subscribe(["Ibm_stocks"])

# Consume messages
while True:
    message = consumer.poll(1.0)

    if message is None:
        continue

    if message.error():
        if message.error().code() == KafkaError._PARTITION_EOF:
            # End of partition, continue to the next
            continue
        else:
            # Handle error
            print("Error occurred: {}".format(message.error()))
            break

    # Print the consumed message
    print("Received message: Key = {}, Value = {}".format(message.key(), message.value()))

consumer.close()

from confluent_kafka import Producer



def read_ccloud_config(file_path):
    # Read the configuration properties from the file
    # and return a dictionary of Kafka configuration
    config = {
        'bootstrap.servers': 'your_bootstrap_servers',
        'schema.registry.url': 'your_schema_registry_url',
        'sasl.mechanisms': 'PLAIN',
        'sasl.username': 'your_sasl_username',
        'sasl.password': 'your_sasl_password',
        'security.protocol': 'SASL_SSL'
    }
    return config



file_path = '/content/client.properties'
producer = Producer(read_ccloud_config(file_path))
producer.produce("Ibm_stocks", key="O3OGN2E2YXGSQTFF", value="51YEWKgezN90BHLRG97EZYowPRJ/3zZhqcyusf9g+A/1yGHecUYi1mWQM4eKejjs")

